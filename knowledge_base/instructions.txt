largely language models they are everywhere they get some things amazingly right and other things very interesting wrong my name is marina done a lot ski i am a senior research scientist here i b m research and i want to tell you about a framework to help largely with models be more accurate and more up to date retrieval augmented generation or rag let's just talk about the generation part for minute so forget the retrieval augmented so the generation this refers to largely with models are elements that generate taxed in response to a user query referred to as a prompt these models can have some undesirable behavior out a tally an anecdote to illustrate this so my kids they read so we ask me this question in our solar system what planet has the most moves and my response was oh that's really great that you're asking this question i loved space when i was your age of course that was like thirty years ago but i know this i read an article i and the article said that it it was jupiter and eighty miles so that's the answer now actually there's a couple of things wrong with my answer first about ah i have no source to support what i'm saying so even though i confidently said i read an article i know the answer i'm not forcing it and giving the answer off the top of my head and also i actually haven't kept up with this for a while oil and my answer is out of date so we have to problems here one is no source and the second problem is that i am out of date and these in fact or to behaviors that are often observed as problematic when interacting with largely with models they are llm challenges now mode of habit of i'd taken to be and first gone and looked up the answer on a reputable source like nasa well then i would have been able to say ah okay so the answer is saturn with one hundred and forty six moves and in fact that keeps changing because i just keep on discovering more more moots so i have now grounded my answer in something more believable i have not hallucinated me up and answer on by the way i didn't leak personal information about how long ago it's been since i was obsessed with space or the what didn't have to do with largely which models mom how would a largely which model had his third this question so let's say that i have a user asking this question about lose allegedly language model wide confidently say okay i am been trained and from what i know in my parameters during my training the answer is jupiter the answer is wrong why you know we don't know their last thing with model is very confident in what unanswered now what happens when you add this retriever which she worked retrieval album entered part here what does i need any that now instead of just relying on what the llm knows we are adding a hunter store his could be open like the internet this can be closed ah like some collection of documents collection of policies whatever the point though now is that the allen first goes and tops to the cotton and store and says hey can you retrieve for me information that is relevant to what the users query was and now with this retriever augmented ah answer not jupiter anymore we know that it is sadder what does this look like wow first user prompts the llm with the question is is as what by question was and originally if we're just talking to a generative model the dreaded model says okay i know the response here it is for my response but now in the ran framework the general model actually has an instruction that says none enough first go and retrieve relevant content combine that with the users question and only then generate the answer so the a prompt now has three parts the instruction to pay attention to the retrieved content together with users question now give a response and in fact now you can give evidence for why your response was what it was so now hopefully you can see how does rad help the to all on challenges that i had mentioned before so first of all along with the out of date part now instead of are having to retrain your model if new information comes up like pay we found some more moves now the jupiter again maybe leaks out of the get in future all you have to do is you all may your or data store with new information up the information so now the next time that a user comes and asks the question already we just go ahead and retrieve the most up to the information the second problem source while the lovely which model as now be instructed to pay attention to primary source data before it is thing it's response and in fact now being able to give evidence this makes it less likely to hallucinate or to leak data because is less likely to rely only on information i learned during training and also allows us to get the model to ah have a behavior back can be very positive which is knowing when to say i don't know if the users question cannot be reliably answered based on your day a store the mall should say i don't know instead of making up something that is believable add may mislead the user this can have a negative effect as well though because if the retriever is not sufficiently good to give the large language model the best most highest quality rounding information then maybe the users cleary that is answerable doesn't get an answer to this is actually why lots of folks including many of us here i b m are working the problem and both sides we are both working to improve the retriever to give the largely which model the best quality god data on which to ground it's response and also the general of part so that be i will on can give the richest best response finally to the user when it generates the answer thank you for learning more about ran and like and subscribe to gel think you